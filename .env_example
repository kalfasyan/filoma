# Filoma Brain Configuration Template
# Copy this file to '.env' and fill in the values for ONE scenario only.
# Comment out all other scenarios to avoid conflicts.

# ==============================================================================
# SCENARIO A: Mistral AI (Cloud - Recommended Default)
# ==============================================================================
# Use this for a "plug and play" European cloud experience.
# Get a key at https://console.mistral.ai/
MISTRAL_API_KEY=
# FILOMA_BRAIN_MODEL=mistral:mistral-small-latest  # Optional override

# ==============================================================================
# SCENARIO B: Ollama (Local - Privacy First)
# ==============================================================================
# Use this for zero-cost, 100% private analysis.
# Requires Ollama app running and 'ollama pull <model>'
# FILOMA_BRAIN_MODEL=ollama:llama3
# FILOMA_BRAIN_BASE_URL=http://localhost:11434/v1

# ==============================================================================
# SCENARIO C: OpenAI (Cloud Fallback)
# ==============================================================================
# OPENAI_API_KEY=

# ==============================================================================
# SCENARIO D: Custom OpenAI-Compatible Provider
# ==============================================================================
# Use this for LocalAI, vLLM, or other 3rd party providers.
# FILOMA_BRAIN_MODEL=your-model-name
# FILOMA_BRAIN_BASE_URL=https://api.provider.com/v1
# FILOMA_BRAIN_API_KEY=your-provider-key
